{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9d3c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Liverpool...\n",
      "get player table for Liverpool\n",
      "get match table for Liverpool\n",
      "Scraping Arsenal...\n",
      "get player table for Arsenal\n",
      "get match table for Arsenal\n",
      "Scraping Manchester City...\n",
      "get player table for Manchester City\n",
      "get match table for Manchester City\n",
      "Scraping Chelsea...\n",
      "get player table for Chelsea\n",
      "get match table for Chelsea\n",
      "Scraping Newcastle Utd...\n",
      "get player table for Newcastle Utd\n",
      "get match table for Newcastle Utd\n",
      "Scraping Aston Villa...\n",
      "get player table for Aston Villa\n",
      "get match table for Aston Villa\n",
      "Scraping Nott'ham Forest...\n",
      "get player table for Nott'ham Forest\n",
      "get match table for Nott'ham Forest\n",
      "Scraping Brighton...\n",
      "get player table for Brighton\n",
      "get match table for Brighton\n",
      "Scraping Bournemouth...\n",
      "get player table for Bournemouth\n",
      "get match table for Bournemouth\n",
      "Scraping Brentford...\n",
      "get player table for Brentford\n",
      "get match table for Brentford\n",
      "Scraping Fulham...\n",
      "get player table for Fulham\n",
      "get match table for Fulham\n",
      "Scraping Crystal Palace...\n",
      "get player table for Crystal Palace\n",
      "get match table for Crystal Palace\n",
      "Scraping Everton...\n",
      "get player table for Everton\n",
      "get match table for Everton\n",
      "Scraping West Ham...\n",
      "get player table for West Ham\n",
      "get match table for West Ham\n",
      "Scraping Manchester Utd...\n",
      "get player table for Manchester Utd\n",
      "get match table for Manchester Utd\n",
      "Scraping Wolves...\n",
      "get player table for Wolves\n",
      "get match table for Wolves\n",
      "Scraping Tottenham...\n",
      "get player table for Tottenham\n",
      "get match table for Tottenham\n",
      "Scraping Leicester City...\n",
      "get player table for Leicester City\n",
      "get match table for Leicester City\n",
      "Scraping Ipswich Town...\n",
      "get player table for Ipswich Town\n",
      "get match table for Ipswich Town\n",
      "Scraping Southampton...\n",
      "get player table for Southampton\n",
      "get match table for Southampton\n",
      "Done. Teams scraped: ['Liverpool', 'Arsenal', 'Manchester City', 'Chelsea', 'Newcastle Utd', 'Aston Villa', \"Nott'ham Forest\", 'Brighton', 'Bournemouth', 'Brentford', 'Fulham', 'Crystal Palace', 'Everton', 'West Ham', 'Manchester Utd', 'Wolves', 'Tottenham', 'Leicester City', 'Ipswich Town', 'Southampton']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://fbref.com/en/comps/9/2024-2025/2024-2025-Premier-League-Stats')\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "teams_names = []\n",
    "\n",
    "teams_table = wait.until(EC.presence_of_element_located((By.ID, 'results2024-202591_overall')))\n",
    "teams = teams_table.find_elements(By.CSS_SELECTOR, 'tbody > tr > .left')\n",
    "\n",
    "for i in range(len(teams)):\n",
    "    teams_table = wait.until(EC.presence_of_element_located((By.ID, 'results2024-202591_overall')))\n",
    "    teams = teams_table.find_elements(By.CSS_SELECTOR, 'tbody > tr > .left')\n",
    "\n",
    "    try:\n",
    "        link = teams[i].find_element(By.TAG_NAME, 'a')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(f\"Scraping {link.text}...\")\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", link)\n",
    "    time.sleep(0.5)\n",
    "    teams_names.append(link.text)\n",
    "\n",
    "    folder_name = link.text.replace(\"/\", \"-\")  # avoid path errors\n",
    "    csv_file = f'{folder_name}_players.csv'\n",
    "    csv_file2 = f'{folder_name}_matchs.csv'\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    csv_file_path = os.path.join(folder_name, csv_file)\n",
    "    csv_file_path2 = os.path.join(folder_name, csv_file2)\n",
    "\n",
    "    time.sleep(1)\n",
    "    link.click()\n",
    "    wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#stats_standard_9 > thead > tr > th')))\n",
    "\n",
    "    # --- PLAYER TABLE ---\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # take only first 16 headers\n",
    "        players_table_header = driver.find_elements(By.CSS_SELECTOR, '#stats_standard_9 > thead > tr > th')[:16]\n",
    "        writer.writerow([h.text.strip() if h.text.strip() else \"-\" for h in players_table_header])\n",
    "\n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, '#stats_standard_9 > tbody > tr')\n",
    "        for row in rows:\n",
    "            cells = [td.text.strip() if td.text.strip() else \"-\" for td in row.find_elements(By.CSS_SELECTOR, \"th, td\")[:16]]\n",
    "            writer.writerow(cells)\n",
    "\n",
    "    print(f\"get player table for {folder_name}\")\n",
    "\n",
    "    # --- MATCH TABLE ---\n",
    "    with open(csv_file_path2, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        matchs_table_header = driver.find_elements(By.CSS_SELECTOR, '#matchlogs_for > thead > tr > th')[:18]\n",
    "        writer.writerow([h.text.strip() if h.text.strip() else \"-\" for h in matchs_table_header])\n",
    "\n",
    "        matchs_rows = driver.find_elements(By.CSS_SELECTOR, '#matchlogs_for > tbody > tr')\n",
    "        for tr in matchs_rows:\n",
    "            cells = [td.text.strip() for td in tr.find_elements(By.CSS_SELECTOR, \"th, td\")[:18]]\n",
    "            writer.writerow(cells)\n",
    "\n",
    "    print(f\"get match table for {folder_name}\")\n",
    "\n",
    "    driver.back()\n",
    "    time.sleep(0.5)\n",
    "    wait.until(EC.presence_of_element_located((By.ID, 'results2024-202591_overall')))\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'tbody > tr > .left > a')))\n",
    "\n",
    "driver.quit()\n",
    "print('Done. Teams scraped:', teams_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
